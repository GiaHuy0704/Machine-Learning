{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB - Tính toán các chỉ số đánh giá từ Ma trận Nhầm lẫn\n",
    "\n",
    "## Giới thiệu\n",
    "Trong học máy và các bài toán phân loại, **ma trận nhầm lẫn** (Confusion Matrix) là một công cụ giúp đánh giá chất lượng của mô hình dự đoán. Ma trận này cho thấy kết quả dự đoán đúng và sai của mô hình.\n",
    "\n",
    "Một ma trận nhầm lẫn cơ bản cho bài toán phân loại nhị phân có dạng:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "TN & FP \\\\\n",
    "FN & TP \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "### Ý nghĩa các chỉ số trong ma trận nhầm lẫn\n",
    "- **True Negative (TN)**: Số lượng mẫu thực tế là **âm** (Negative) và mô hình cũng dự đoán là **âm**.\n",
    "- **False Positive (FP)**: Số lượng mẫu thực tế là **âm** nhưng mô hình lại dự đoán là **dương** (Positive). Đây còn gọi là **dương giả**.\n",
    "- **False Negative (FN)**: Số lượng mẫu thực tế là **dương** nhưng mô hình lại dự đoán là **âm**. Đây còn gọi là **âm giả**.\n",
    "- **True Positive (TP)**: Số lượng mẫu thực tế là **dương** và mô hình cũng dự đoán là **dương**.\n",
    "\n",
    "Các giá trị này có thể tính toán được nhiều chỉ số quan trọng, giúp đánh giá mô hình một cách toàn diện.\n",
    "\n",
    "## Các Chỉ số Đánh giá Hiệu quả Mô Hình\n",
    "\n",
    "### 1. Độ chính xác (Accuracy)\n",
    "**Độ chính xác** là tỷ lệ số dự đoán đúng trên tổng số mẫu. Chỉ số này cho biết mô hình dự đoán chính xác bao nhiêu phần trăm.\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "### 2. Độ nhạy (Recall) \n",
    "**Độ nhạy** hay còn gọi là **Tỷ lệ phát hiện dương** (Sensitivity) cho biết mô hình phát hiện đúng bao nhiêu phần trăm các mẫu dương. Độ nhạy đặc biệt quan trọng khi chúng ta muốn giảm thiểu số trường hợp **âm giả**.\n",
    "$$\n",
    "\\text{Recall} = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "Ví dụ, nếu đang xây dựng mô hình chẩn đoán bệnh, Recall cao có nghĩa là mô hình không bỏ sót quá nhiều ca bệnh.\n",
    "\n",
    " Giải thích :\n",
    "- recall là tỷ lệ phát hiện đúng các mẫu dương.\n",
    "- Trong trường hợp chẩn đoán bệnh, các mẫu dương là các ca bệnh thực sự.\n",
    "- recall cao có nghĩa là mô hình phát hiện được hầu hết các ca bệnh, tức là không bỏ sót nhiều ca bệnh\n",
    "\n",
    "### 3. Độ đặc hiệu (Specificity)\n",
    "**Độ đặc hiệu** là tỷ lệ dự đoán đúng các mẫu âm trên tổng số các mẫu âm thực tế. Chỉ số này cho biết mô hình có khả năng nhận diện đúng các mẫu âm tốt như thế nào.\n",
    "$$\n",
    "\\text{Specificity} = \\frac{TN}{TN + FP}\n",
    "$$\n",
    "\n",
    "Ví dụ, trong mô hình phát hiện gian lận, Specificity cao tránh được các trường hợp báo động sai (dương giả).\n",
    "\n",
    "Giải thích: \n",
    "- Specificity là tỷ lệ dự đoán đúng các mẫu âm\n",
    "- Trong trường hợp phát hiện gian lận, các mẫu âm là các giao dịch không gian lận\n",
    "- Specificity cao có nghĩa là mô hình nhận diện đúng hầu hết các giao dịch không gian lận, tức là giảm thiểu các trường hợp báo động sai (False Positive)\n",
    "\n",
    "### 4. Giá trị dự đoán dương (Precision)\n",
    "**Precision** hay còn gọi là **Độ chính xác của các dự đoán dương** là tỷ lệ dự đoán đúng trong số tất cả các mẫu được dự đoán là dương. Precision đặc biệt quan trọng khi chi phí của việc dương giả cao.\n",
    "$$\n",
    "\\text{Precision} = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "Ví dụ, trong mô hình phát hiện ung thư, Precision cao đảm bảo rằng những trường hợp bị đánh dấu là dương (bệnh nhân mắc ung thư) có khả năng mắc bệnh thực sự.\n",
    "\n",
    "Giải thích:\n",
    "- Precision là tỷ lệ dự đoán đúng trong số tất cả các mẫu được dự đoán là dương\n",
    "- Trong trường hợp phát hiện ung thư, các mẫu dương là các bệnh nhân được dự đoán mắc ung thư\n",
    "- Precision cao có nghĩa là hầu hết các bệnh nhân được dự đoán mắc ung thư thực sự mắc bệnh, tức là giảm thiểu các trường hợp dương giả (False Positive)\n",
    "\n",
    "### 5. F1-Score\n",
    "**F1 Score** là trung bình điều hòa giữa Precision và Recall. Chỉ số này hữu ích khi cần cân bằng giữa Recall và Precision, đặc biệt trong các bài toán mà một chỉ số cao hơn có thể dẫn đến một chỉ số khác bị giảm.\n",
    "$$\n",
    "F1 = \\frac{2 \\times \\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "F1 Score giúp đánh giá mô hình với dữ liệu không cân bằng, chẳng hạn như khi số lượng mẫu dương và âm chênh lệch đáng kể.\n",
    "\n",
    "## Tóm tắt\n",
    "| Chỉ số       | Công thức                                       | Ý nghĩa |\n",
    "|--------------|-------------------------------------------------|---------|\n",
    "| Accuracy     | $$\\frac{TP + TN}{TP + TN + FP + FN}$$           | Tỷ lệ dự đoán đúng trên tổng số mẫu |\n",
    "| Recall       | $$\\frac{TP}{TP + FN}$$                          | Tỷ lệ phát hiện đúng các mẫu dương |\n",
    "| Specificity  | $$\\frac{TN}{TN + FP}$$                          | Tỷ lệ phát hiện đúng các mẫu âm |\n",
    "| Precision    | $$\\frac{TP}{TP + FP}$$                          | Tỷ lệ các dự đoán dương chính xác |\n",
    "| F1-Score     | $$\\frac{2 \\times \\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$ | Cân bằng giữa Precision và Recall |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài tập nhẹ nhàng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cho ma trận nhầm lẫn sau: \n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "50 & 10 \\\\\n",
    "5 & 30 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Định nghĩa ma trận nhầm lẫn\n",
    "2. Tính toán các chỉ số\n",
    "3. In kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[50 10]\n",
      " [5 30]]\n",
      "Accuracy: 0.84\n",
      "Recall: 0.86\n",
      "Specificity: 0.83\n",
      "Precision: 0.75\n",
      "F1 Score: 0.80\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Định nghĩa ma trận nhầm lẫn\n",
    "TN = 50 #code here\n",
    "FP = 10 #code here\n",
    "FN = 5 #code here\n",
    "TP = 30 #code here\n",
    "# Tính toán các chỉ số\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN) #code here\n",
    "recall = TP / (TP + FN)#code here\n",
    "specificity = TN / (TN + FP)#code here \n",
    "precision = TP / (TP + FP) #code here\n",
    "f1 = 2 * (precision * recall) / (precision + recall)#code here\n",
    "# In kết quả\n",
    "print(f\"Confusion Matrix:\\n[[{TN} {FP}]\\n [{FN} {TP}]]\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"Specificity: {specificity:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1860540728.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    ---\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Nhận xét ở đây:\n",
    "---\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bài tập nâng cao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sủ dụng Markfown để viết ra 4 chỉ số tính độ chính xác, và viết định nghĩa cho các công thức sau:\n",
    "\n",
    "1. Balanced Accuracy\n",
    "2. Matthews Correlation Coefficient (MCC)\n",
    "3. Fowlkes-Mallows Index (FMI)\n",
    "4. Bias\n",
    "\n",
    "### Ứng dụng 4 chỉ số này để tính toán cho bài tập nhẹ nhàng ở trên"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tóm tắt\n",
    "| Chỉ số       | Công thức                                       | Ý nghĩa |\n",
    "|--------------|-------------------------------------------------|---------|\n",
    "| Banlanced Accuracy      | Banlanced Accuracy = $$\\frac{\\text{Sensitivity} + \\text{Specificity}}{2} = \\frac{TPR + TNR}{2}$$           | Balanced Accuracy là một chỉ số được sử dụng để đo lường độ chính xác của mô hình, đặc biệt là khi dữ liệu không cân bằng. Nó là trung bình của độ nhạy (recall) và độ chính xác âm (specificity). |\n",
    "|  Matthews Correlation Coefficient (MCC)  | $$\\text{MCC} = \\frac{(TP \\times TN) - (FP \\times FN)}{\\sqrt{(TP + FP)(TP + FN)(TN + FP)(TN + FN)}}$$                          | Matthews Correlation Coefficient (MCC) là một chỉ số được sử dụng để đánh giá chất lượng của các phân loại nhị phân. MCC là một số từ -1 đến +1, trong đó +1 thể hiện một phân loại hoàn hảo, 0 thể hiện phân loại ngẫu nhiên và -1 thể hiện phân loại hoàn toàn sai. |\n",
    "| Fowlkes-Mallows Index (FMI)  | $$\\text{FMI} = \\frac{TP}{\\sqrt{(TP + FP)(TP + FN)}}$$                          | Fowlkes-Mallows Index (FMI) là một chỉ số đánh giá độ chính xác của các phân loại nhị phân. Nó là căn bậc hai của tích của độ chính xác và độ nhạy, cung cấp một cái nhìn tổng quan về hiệu suất của mô hình. |\n",
    "| Bias    | $$\\text{Bias} = \\frac{(TP + FP) - (TP + FN)}{TP + FP + TN + FN}$$ | Bias là một chỉ số đo lường độ thiên lệch của các dự đoán so với thực tế. Một bias dương có nghĩa là mô hình có xu hướng dự đoán các lớp dương nhiều hơn so với thực tế, trong khi một bias âm có nghĩa là mô hình có xu hướng dự đoán các lớp âm nhiều hơn. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bài tập vận dụng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature 1  Feature 2\n",
      "0   3.069402   5.612889\n",
      "1  -0.355127  -1.005306\n",
      "2   1.213291   2.977067\n",
      "3   1.521887   2.125014\n",
      "4   3.522842   2.539153\n",
      "Nhãn tương ứng: [1. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Tạo dữ liệu giả định cho KNN\n",
    "np.random.seed(42)\n",
    "data_size = 1000\n",
    "# Tạo các đặc trưng ngẫu nhiên giữa các lớp\n",
    "X_class0 = np.random.multivariate_normal([2, 2], [[1.5, 0.75], [0.75, 1.5]], data_size // 2)\n",
    "X_class1 = np.random.multivariate_normal([4, 4], [[1.5, 0.75], [0.75, 1.5]], data_size // 2)\n",
    "X = np.vstack((X_class0, X_class1))\n",
    "y = np.hstack((np.zeros(data_size // 2), np.ones(data_size // 2)))\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra với test = 30 và random = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)# Hiển thị một vài mẫu dữ liệu\n",
    "print(pd.DataFrame(X_train[:5], columns=[\"Feature 1\", \"Feature 2\"]))\n",
    "print(\"Nhãn tương ứng:\", y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(a, b):\n",
    "    return  np.sqrt(np.sum((a - b) ** 2)) #code here\n",
    "def knn_predict(X_train, y_train, X_test, k=5):\n",
    "    y_pred = []\n",
    "    for test_point in X_test:\n",
    "        distances = [euclidean_distance(test_point, x) for x in X_train]\n",
    "        k_indices = np.argsort(distances)[:k]\n",
    "        k_nearest_labels = [y_train[i] for i in k_indices]\n",
    "        most_common = max(set(k_nearest_labels), key=k_nearest_labels.count)\n",
    "        y_pred.append(most_common)#code here\n",
    "    return np.array(y_pred)\n",
    "# Dự đoán trên tập kiểm tra với k = 5\n",
    "k = 5\n",
    "y_pred_knn = knn_predict(X_train, y_train, X_test, k=5)#code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model Evaluation:\n",
      "Confusion Matrix:\n",
      "[[116  34]\n",
      " [ 16 134]]\n",
      "Accuracy: 0.83\n",
      "Recall: 0.89\n",
      "Specificity: 0.77\n",
      "Precision: 0.80\n",
      "F1 Score: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Định nghĩa hàm confusion_matrix\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))#code here\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))#code here\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))#code here\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))#code here\n",
    "    return np.array([[TN, FP], [FN, TP]])#code here\n",
    "\n",
    "# Hàm tính toán và in các chỉ số\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)#code here\n",
    "    recall = TP / (TP + FN)#code here\n",
    "    specificity = TN / (TN + FP)#code here\n",
    "    precision = TP / (TP + FP)#code here\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"Specificity: {specificity:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "# Đánh giá mô hình KNN\n",
    "print(\"KNN Model Evaluation:\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Tạo dữ liệu giả định cho KNN\n",
    "np.random.seed(42)\n",
    "data_size = 1000\n",
    "# Tạo các đặc trưng ngẫu nhiên giữa các lớp\n",
    "X_class0 = np.random.multivariate_normal([2, 2], [[1.5, 0.75], [0.75, 1.5]], data_size // 2)\n",
    "X_class1 = np.random.multivariate_normal([4, 4], [[1.5, 0.75], [0.75, 1.5]], data_size // 2)\n",
    "X = np.vstack((X_class0, X_class1))\n",
    "y = np.hstack((np.zeros(data_size // 2), np.ones(data_size // 2)))\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra với test_size = 0.3 và random_state = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Hiển thị một vài mẫu dữ liệu\n",
    "print(pd.DataFrame(X_train[:5], columns=[\"Feature 1\", \"Feature 2\"]))\n",
    "print(\"Nhãn tương ứng:\", y_train[:5])\n",
    "\n",
    "# Định nghĩa hàm tính khoảng cách Euclidean\n",
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt(np.sum((a - b) ** 2))\n",
    "\n",
    "# Định nghĩa hàm KNN\n",
    "def knn_predict(X_train, y_train, X_test, k=5):\n",
    "    y_pred = []\n",
    "    for test_point in X_test:\n",
    "        distances = [euclidean_distance(test_point, x) for x in X_train]\n",
    "        k_indices = np.argsort(distances)[:k]\n",
    "        k_nearest_labels = [y_train[i] for i in k_indices]\n",
    "        most_common = max(set(k_nearest_labels), key=k_nearest_labels.count)\n",
    "        y_pred.append(most_common)\n",
    "    return np.array(y_pred)\n",
    "\n",
    "# Dự đoán trên tập kiểm tra với k = 5\n",
    "y_pred_knn = knn_predict(X_train, y_train, X_test, k=5)\n",
    "\n",
    "# Định nghĩa hàm confusion_matrix\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    return np.array([[TN, FP], [FN, TP]])\n",
    "\n",
    "# Hàm tính toán và in các chỉ số\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    recall = TP / (TP + FN)\n",
    "    specificity = TN / (TN + FP)\n",
    "    precision = TP / (TP + FP)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"Specificity: {specificity:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# Đánh giá mô hình KNN\n",
    "print(\"KNN Model Evaluation:\")\n",
    "evaluate_model(y_test, y_pred_knn)#code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài tập về nhà"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tải tập dữ liệu Wine từ sklearn.datasets và chia tập dữ liệu theo tỷ lệ 70:30. Xây dựng mô hình KNN để phân loại dữ liệu. Sử dụng k = 5. Tính toán và in ra độ chính xác, recall, và precision của mô hình\n",
    "### Xây dựng website để trực quan hóa kết quả và độ chính xác"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
